{
  "activation": "relu",
  "layers": [
    128,
    128
  ]
}
