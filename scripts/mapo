#! /usr/bin/env python3

"""MAPO running script."""

# pylint: disable=import-self, no-name-in-module

import argparse
import json
import ray
from ray import tune
from mapo import register_all_agents, register_all_environments
from mapo.version import __version__


def read_config_json(filepath):
    """Load JSON object from file."""
    with open(filepath, "r") as file:
        return json.loads(file.read())


def parse_args():
    """Parse command-line arguments."""
    description = "Model-Aware Policy Optimization ({})".format(__version__)
    usage = "%(prog)s --run {MAPO,OffMAPO} --env ENV [ENV ...] [CONFIG-OPTIONS]"

    parser = argparse.ArgumentParser(usage=usage, description=description)

    parser.add_argument(
        "--run",
        type=str,
        choices=["MAPO", "OffMAPO", "OurTD3"],
        required=True,
        help="The algorithm or model to train.",
    )
    parser.add_argument(
        "--env",
        type=str,
        nargs="+",
        default=[],
        required=True,
        help="The gym environment to use.",
    )
    parser.add_argument(
        "--verbose",
        type=int,
        choices=[0, 1, 2],
        default=2,
        help="0, 1, or 2. Verbosity mode. 0 = silent, "
        "1 = only status updates, 2 = status and trial results "
        "(default=2)",
    )

    mapo_args_group = parser.add_argument_group(">> MAPO")
    mapo_args_group.add_argument(
        "--kernel",
        type=str,
        choices=["l1", "l2", "linf", "dot-product", "cos-similarity"],
        default="l2",
        help="Kernel metric to compare gradients in MAPO.",
    )
    mapo_args_group.add_argument(
        "--use-true-dynamics",
        action="store_true",
        default=False,
        help="Flag to use the true dyamics log prob in the gradient estimator "
        "(default=False)",
    )
    mapo_args_group.add_argument(
        "--branching-factor",
        type=int,
        default=32,
        help="The number of virtual samples used in MAPO gradient " "(default=32)",
    )
    mapo_args_group.add_argument(
        "--model-loss",
        type=str,
        choices=["mle", "pga"],
        default="pga",
        help="The loss function used for learning the dynamics model " "(default=pga)",
    )

    model_args_group = parser.add_argument_group(">> Models")
    model_args_group.add_argument(
        "--config-actor-net",
        type=read_config_json,
        help="The actor network configuration JSON file.",
    )
    model_args_group.add_argument(
        "--config-critic-net",
        type=read_config_json,
        help="The critic network configuration JSON file.",
    )
    model_args_group.add_argument(
        "--config-dynamics-net",
        type=read_config_json,
        help="The dynamics network configuration JSON file.",
    )

    optimizers_args_group = parser.add_argument_group(">> Optimization")
    optimizers_args_group.add_argument(
        "--num-sgd-iter",
        type=int,
        default=80,
        help="The number of SGD optimizer iterations (defaul=80).",
    )
    optimizers_args_group.add_argument(
        "--actor-lr",
        type=float,
        default=1e-3,
        help="The learning rate for the actor (policy) optimizer " "(defaul=1e-3).",
    )
    optimizers_args_group.add_argument(
        "--critic-lr",
        type=float,
        default=1e-3,
        help="The learning rate for the critic (Q-function) optimizer "
        "(defaul=1e-3).",
    )
    optimizers_args_group.add_argument(
        "--dynamics-lr",
        type=float,
        default=1e-3,
        help="The learning rate for the dynamics optimizer (defaul=1e-3).",
    )
    optimizers_args_group.add_argument(
        "--actor-delay",
        type=int,
        default=80,
        help="The number of traing steps before updating the policy " "(default=8).",
    )
    optimizers_args_group.add_argument(
        "--critic-delay",
        type=int,
        default=1,
        help="The number of traing steps before updating the critic " "(default=1).",
    )
    optimizers_args_group.add_argument(
        "--dynamics-delay",
        type=int,
        default=20,
        help="The number of traing steps before updating the dynamics" "(default=1).",
    )

    exec_args_group = parser.add_argument_group(">> Execution")
    exec_args_group.add_argument(
        "--timesteps-total",
        type=int,
        default=int(1e5),
        help="The total number of timesteps (default=100K).",
    )
    exec_args_group.add_argument(
        "--sample-batch-size",
        type=int,
        default=1,
        help="The size of the batch collected by workers (default=1).",
    )
    exec_args_group.add_argument(
        "--train-batch-size",
        type=int,
        default=128,
        help="The size of the batch for training (default=128).",
    )

    resources_args_group = parser.add_argument_group(">> Resources")
    resources_args_group.add_argument(
        "--num-cpus-for-driver",
        type=int,
        default=1,
        help="The number of CPUs to allocate to the driver (default=1).",
    )
    resources_args_group.add_argument(
        "--num-gpus",
        type=float,
        default=0.0,
        help="The number of GPUs to allocate to the driver (default=0.0).",
    )
    resources_args_group.add_argument(
        "--num-workers",
        type=int,
        default=0,
        help="The number of actors used for parallelism (default=0).",
    )
    resources_args_group.add_argument(
        "--num-cpus-per-worker",
        type=int,
        default=1,
        help="The number of CPUs to allocate to each worker (default=1).",
    )
    resources_args_group.add_argument(
        "--num-gpus-per-worker",
        type=float,
        default=0.0,
        help="The number of GPUs to allocate to each worker (default=0.0).",
    )
    resources_args_group.add_argument(
        "--num-envs-per-worker",
        type=int,
        default=8,
        help="The number of envs per worker used for parallelism (default=8).",
    )

    eval_args_group = parser.add_argument_group(">> Evaluation")
    eval_args_group.add_argument(
        "--evaluation-interval",
        type=int,
        default=10,
        help="The interval between training steps for evaluation " "(default=10)",
    )
    eval_args_group.add_argument(
        "--evaluation-num-episodes",
        type=int,
        default=10,
        help="The number of episodes to run per evaluation period " "(default=10)",
    )

    exp_args_group = parser.add_argument_group(">> Experiment")
    exp_args_group.add_argument(
        "--num-samples",
        type=int,
        default=1,
        help="The number of times to sample from the hyperparameter space "
        "(default=1).",
    )
    exp_args_group.add_argument("--name", type=str, help="The name of the experiment.")

    return parser.parse_args()


def init():
    """Initialize ray framework."""
    ray.init()


def register():
    """Register all agents and custom environtments."""
    register_all_agents()
    register_all_environments()


def make_config(args):
    """Make config dict to trainer."""

    # === Environment ===
    env_config = {"env": tune.grid_search(args.env)}

    # === MAPO ===
    mapo_config = {}
    if args.run in ["MAPO", "OffMAPO"]:
        mapo_config = {
            "branching_factor": args.branching_factor,
            "use_true_dynamics": args.use_true_dynamics,
            "model_loss": args.model_loss,
        }

    # === Models ===
    models_config = {
        "model": {
            "custom_model": "mapo_model",
            "custom_options": {
                "actor": args.config_actor_net,
                "critic": args.config_critic_net,
            },
        }
    }
    if args.run in ["MAPO", "OffMAPO"]:
        models_config["model"]["custom_model"] = "mapo_model"

        if not args.use_true_dynamics:
            models_config["model"]["custom_options"][
                "dynamics"
            ] = args.config_dynamics_net

    elif args.run == "OurTD3":
        models_config["model"]["custom_model"] = "td3_model"

    # === Preprocessing ===
    preprocessing_config = {"observation_filter": "NoFilter"}

    # === Optimization ===
    optimization_config = {
        "actor_lr": args.actor_lr,
        "critic_lr": args.critic_lr,
        "actor_delay": args.actor_delay,
    }
    if args.run == "MAPO":
        optimization_config["optimizer"] = {"num_sgd_iter": args.num_sgd_iter}

    if args.run in ["MAPO", "OffMAPO"]:
        optimization_config["critic_delay"] = args.critic_delay

        if not args.use_true_dynamics:
            optimization_config["dynamics_lr"] = args.dynamics_lr

    # === Execution ===
    execution_config = {
        "batch_mode": "complete_episodes",
        "sample_batch_size": args.sample_batch_size,
        "train_batch_size": args.train_batch_size,
    }

    # === Resources ===
    resources_config = {
        "num_cpus_for_driver": args.num_cpus_for_driver,
        "num_gpus": args.num_gpus,
        "num_workers": args.num_workers,
        "num_cpus_per_worker": args.num_cpus_per_worker,
        "num_gpus_per_worker": args.num_gpus_per_worker,
        "num_envs_per_worker": args.num_envs_per_worker,
    }

    # === Evaluation ===
    eval_config = {}
    if args.run in ["OffMAPO", "OurTD3"]:
        eval_config["evaluation_interval"] = args.evaluation_interval
        eval_config["evaluation_num_episodes"] = args.evaluation_num_episodes

    # === TF Session ===
    tf_session_config = {"tf_session_args": {"log_device_placement": True}}

    return {
        **env_config,
        **preprocessing_config,
        **mapo_config,
        **models_config,
        **optimization_config,
        **execution_config,
        **resources_config,
        **eval_config,
        **tf_session_config,
    }


def run(args):
    """Run experiments with configuration given by command-line arguments."""
    trainer = args.run
    experiment = args.name

    analysis = tune.run(
        trainer,
        name=experiment,
        verbose=args.verbose,
        stop={"timesteps_total": args.timesteps_total},
        num_samples=args.num_samples,
        config=make_config(args),
        checkpoint_freq=10,
        checkpoint_at_end=True,
    )

    return analysis


def report(analysis):
    """Report analysis for best configuraion in experiments."""
    best_config = analysis.get_best_config("episode_reward_mean", mode="max")
    best_logdir = analysis.get_best_logdir("episode_reward_mean", mode="max")

    print(">> Best configuration:")
    print(json.dumps(best_config, indent=2, sort_keys=True))
    print()

    print("tensorboard --logdir={}".format(best_logdir))
    print()


if __name__ == "__main__":
    # pylint: disable=invalid-name

    arguments = parse_args()

    init()
    register()

    results = run(arguments)
    report(results)
